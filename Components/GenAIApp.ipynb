{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae946b3",
   "metadata": {},
   "source": [
    "# Simple Gen AI App using Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b8bb62",
   "metadata": {},
   "source": [
    "# # Load Data --> Docs  -->Divide our text into chunks --> Vectors --> Vector Embeddings --> Vector Store DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8a8ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all The Libraries and API Keys\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "import streamlit \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d637d1d1",
   "metadata": {},
   "source": [
    "# load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498eddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Ingestion--> From the website we need to scrap the data\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui\")\n",
    "final_load = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f41191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content=\"Prompt engineering quickstart - Docs by LangChainSkip to main contentðŸš€ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangSmithSearch...âŒ˜KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationPrompt engineering quickstartGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupReferenceOverviewQuickstartConceptsCreate and update promptsCreate a promptManage promptsManage prompts programmaticallyConfigure prompt settingsUse tools in a promptInclude multimodal content in a promptWrite your prompt with AIConnect to modelsTutorialsOptimize a classifierSync prompts with GitHubTest multi-turn conversationsOn this pagePrerequisitesNext stepsVideo guidePrompt engineering quickstartCopy pageCopy pagePrompts guide the behavior of Large Language Models (LLM). Prompt engineering is the process of crafting, testing, and refining the instructions you give to an LLM so it produces reliable and useful responses.\\nLangSmith provides tools to create, version, test, and collaborate on prompts. Youâ€™ll also encounter common concepts like prompt templates, which let you reuse structured prompts, and variables, which allow you to dynamically insert values (such as a userâ€™s question) into a prompt.\\nIn this quickstart, youâ€™ll create, test, and improve prompts using either the UI or the SDK. This quickstart will use OpenAI as the example LLM provider, but the same workflow applies across other providers.\\nIf you prefer to watch a video on getting started with prompt engineering, refer to the quickstart Video guide.\\n\\u200bPrerequisites\\nBefore you begin, make sure you have:\\n\\nA LangSmith account: Sign up or log in at smith.langchain.com.\\nA LangSmith API key: Follow the Create an API key guide.\\nAn OpenAI API key: Generate this from the OpenAI dashboard.\\n\\nSelect the tab for UI or SDK workflows:\\n UI SDK\\u200b1. Set workspace secretIn the LangSmith UI, ensure that your OpenAI API key is set as a workspace secret.\\nNavigate to  Settings and then move to the Secrets tab.\\nSelect Add secret and enter the OPENAI_API_KEY and your API key as the Value.\\nSelect Save secret.\\n When adding workspace secrets in the LangSmith UI, make sure the secret keys match the environment variable names expected by your model provider.\\u200b2. Create a prompt\\nIn the LangSmith UI, navigate to the Prompts section in the left-hand menu.\\nClick on + Prompt to create a prompt.\\nModify the prompt by editing or adding prompts and input variables as needed.\\n\\u200b3. Test a prompt\\n\\nUnder the Prompts heading select the gear  icon next to the model name, which will launch the Prompt Settings window on the Model Configuration tab.\\n\\n\\nSet the model configuration you want to use. The Provider and Model you select will determine the parameters that are configurable on this configuration page. Once set, click Save as.\\n\\n\\n\\nSpecify the input variables you would like to test in the Inputs box and then click  Start.\\n\\nTo learn about more options for configuring your prompt in the Playground, refer to Configure prompt settings.\\n\\n\\nAfter testing and refining your prompt, click Save to store it for future use.\\n\\n\\u200b4. Iterate on a promptLangSmith allows for team-based prompt iteration. Workspace members can experiment with prompts in the playground and save their changes as a new commit when ready.To improve your prompts:\\n\\nReference the documentation provided by your model provider for best practices in prompt creation, such as:\\n\\nBest practices for prompt engineering with the OpenAI API\\nGeminiâ€™s Introduction to prompt design\\n\\n\\n\\nBuild and refine your prompts with the Prompt Canvasâ€”an interactive tool in LangSmith. Learn more in the Prompt Canvas guide.\\n\\n\\nTag specific commits to mark important moments in your commit history.\\n\\nTo create a commit, navigate to the Playground and select Commit. Choose the prompt to commit changes to and then Commit.\\nNavigate to Prompts in the left-hand menu. Select the prompt. Once on the promptâ€™s detail page, move to the Commits tab. Find the tag icon  to Add a Commit Tag.\\n\\n\\n\\n\\n\\u200bNext steps\\n\\nLearn more about how to store and manage prompts using the Prompt Hub in the Create a prompt guide.\\nLearn how to set up the Playground to Test multi-turn conversations in this tutorial.\\nLearn how to test your promptâ€™s performance over a dataset instead of individual examples, refer to Run an evaluation from the Prompt Playground.\\n\\n\\u200bVideo guide\\n\\n\\nEdit the source of this page on GitHub.\\nConnect these docs programmatically to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoPrompt engineeringPreviousPrompt engineering conceptsNextâŒ˜IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b9737",
   "metadata": {},
   "source": [
    "# Divides the data into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5f17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data --> Docs  -->Divide our text into chunks --> Vectors --> Vector Embeddings --> Vector Store DB\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "web_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=200)\n",
    "\n",
    "final_split = web_splitter.split_documents(final_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba55fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content=\"Prompt engineering quickstart - Docs by LangChainSkip to main contentðŸš€ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangSmithSearch...âŒ˜KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationPrompt engineering quickstartGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupReferenceOverviewQuickstartConceptsCreate and update promptsCreate a promptManage promptsManage prompts programmaticallyConfigure prompt settingsUse tools in a promptInclude multimodal content in a promptWrite your prompt with AIConnect to modelsTutorialsOptimize a classifierSync prompts with GitHubTest multi-turn conversationsOn this pagePrerequisitesNext stepsVideo guidePrompt engineering quickstartCopy pageCopy pagePrompts guide the behavior of Large Language Models (LLM). Prompt engineering is the process of crafting, testing, and refining the instructions you give to an LLM so it produces reliable and useful responses.\"),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content='LangSmith provides tools to create, version, test, and collaborate on prompts. Youâ€™ll also encounter common concepts like prompt templates, which let you reuse structured prompts, and variables, which allow you to dynamically insert values (such as a userâ€™s question) into a prompt.\\nIn this quickstart, youâ€™ll create, test, and improve prompts using either the UI or the SDK. This quickstart will use OpenAI as the example LLM provider, but the same workflow applies across other providers.\\nIf you prefer to watch a video on getting started with prompt engineering, refer to the quickstart Video guide.\\n\\u200bPrerequisites\\nBefore you begin, make sure you have:'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content='A LangSmith account: Sign up or log in at smith.langchain.com.\\nA LangSmith API key: Follow the Create an API key guide.\\nAn OpenAI API key: Generate this from the OpenAI dashboard.\\n\\nSelect the tab for UI or SDK workflows:\\n UI SDK\\u200b1. Set workspace secretIn the LangSmith UI, ensure that your OpenAI API key is set as a workspace secret.\\nNavigate to  Settings and then move to the Secrets tab.\\nSelect Add secret and enter the OPENAI_API_KEY and your API key as the Value.\\nSelect Save secret.\\n When adding workspace secrets in the LangSmith UI, make sure the secret keys match the environment variable names expected by your model provider.\\u200b2. Create a prompt\\nIn the LangSmith UI, navigate to the Prompts section in the left-hand menu.\\nClick on + Prompt to create a prompt.\\nModify the prompt by editing or adding prompts and input variables as needed.\\n\\u200b3. Test a prompt'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content='Under the Prompts heading select the gear  icon next to the model name, which will launch the Prompt Settings window on the Model Configuration tab.\\n\\n\\nSet the model configuration you want to use. The Provider and Model you select will determine the parameters that are configurable on this configuration page. Once set, click Save as.\\n\\n\\n\\nSpecify the input variables you would like to test in the Inputs box and then click  Start.\\n\\nTo learn about more options for configuring your prompt in the Playground, refer to Configure prompt settings.\\n\\n\\nAfter testing and refining your prompt, click Save to store it for future use.\\n\\n\\u200b4. Iterate on a promptLangSmith allows for team-based prompt iteration. Workspace members can experiment with prompts in the playground and save their changes as a new commit when ready.To improve your prompts:\\n\\nReference the documentation provided by your model provider for best practices in prompt creation, such as:'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content='Reference the documentation provided by your model provider for best practices in prompt creation, such as:\\n\\nBest practices for prompt engineering with the OpenAI API\\nGeminiâ€™s Introduction to prompt design\\n\\n\\n\\nBuild and refine your prompts with the Prompt Canvasâ€”an interactive tool in LangSmith. Learn more in the Prompt Canvas guide.\\n\\n\\nTag specific commits to mark important moments in your commit history.\\n\\nTo create a commit, navigate to the Playground and select Commit. Choose the prompt to commit changes to and then Commit.\\nNavigate to Prompts in the left-hand menu. Select the prompt. Once on the promptâ€™s detail page, move to the Commits tab. Find the tag icon  to Add a Commit Tag.\\n\\n\\n\\n\\n\\u200bNext steps'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content='\\u200bNext steps\\n\\nLearn more about how to store and manage prompts using the Prompt Hub in the Create a prompt guide.\\nLearn how to set up the Playground to Test multi-turn conversations in this tutorial.\\nLearn how to test your promptâ€™s performance over a dataset instead of individual examples, refer to Run an evaluation from the Prompt Playground.\\n\\n\\u200bVideo guide\\n\\n\\nEdit the source of this page on GitHub.\\nConnect these docs programmatically to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoPrompt engineeringPreviousPrompt engineering conceptsNextâŒ˜IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de0cb23",
   "metadata": {},
   "source": [
    "# Converting Small Chunks into Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7a7d043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaEmbeddings(base_url='http://localhost:11434', model='gemma:2b', embed_instruction='passage: ', query_instruction='query: ', mirostat=None, mirostat_eta=None, mirostat_tau=None, num_ctx=None, num_gpu=None, num_thread=None, repeat_last_n=None, repeat_penalty=None, temperature=None, stop=None, tfs_z=None, top_k=None, top_p=None, show_progress=False, headers=None, model_kwargs=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"gemma:2b\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610fff2a",
   "metadata": {},
   "source": [
    "# Setup Faiss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e279149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2d395ffc920>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "db = FAISS.from_documents(final_split,embeddings)\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c92d18",
   "metadata": {},
   "source": [
    "# Query Perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bf32c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='4a240d51-7030-4e21-bb82-f0ed7de2314a', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content='Under the Prompts heading select the gear  icon next to the model name, which will launch the Prompt Settings window on the Model Configuration tab.\\n\\n\\nSet the model configuration you want to use. The Provider and Model you select will determine the parameters that are configurable on this configuration page. Once set, click Save as.\\n\\n\\n\\nSpecify the input variables you would like to test in the Inputs box and then click  Start.\\n\\nTo learn about more options for configuring your prompt in the Playground, refer to Configure prompt settings.\\n\\n\\nAfter testing and refining your prompt, click Save to store it for future use.\\n\\n\\u200b4. Iterate on a promptLangSmith allows for team-based prompt iteration. Workspace members can experiment with prompts in the playground and save their changes as a new commit when ready.To improve your prompts:\\n\\nReference the documentation provided by your model provider for best practices in prompt creation, such as:'),\n",
       " Document(id='3fcc34c6-3631-4d98-a647-0458c23eadea', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content='Reference the documentation provided by your model provider for best practices in prompt creation, such as:\\n\\nBest practices for prompt engineering with the OpenAI API\\nGeminiâ€™s Introduction to prompt design\\n\\n\\n\\nBuild and refine your prompts with the Prompt Canvasâ€”an interactive tool in LangSmith. Learn more in the Prompt Canvas guide.\\n\\n\\nTag specific commits to mark important moments in your commit history.\\n\\nTo create a commit, navigate to the Playground and select Commit. Choose the prompt to commit changes to and then Commit.\\nNavigate to Prompts in the left-hand menu. Select the prompt. Once on the promptâ€™s detail page, move to the Commits tab. Find the tag icon  to Add a Commit Tag.\\n\\n\\n\\n\\n\\u200bNext steps'),\n",
       " Document(id='211feef6-6215-4e16-bf9a-0a9d5da9a393', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content='A LangSmith account: Sign up or log in at smith.langchain.com.\\nA LangSmith API key: Follow the Create an API key guide.\\nAn OpenAI API key: Generate this from the OpenAI dashboard.\\n\\nSelect the tab for UI or SDK workflows:\\n UI SDK\\u200b1. Set workspace secretIn the LangSmith UI, ensure that your OpenAI API key is set as a workspace secret.\\nNavigate to  Settings and then move to the Secrets tab.\\nSelect Add secret and enter the OPENAI_API_KEY and your API key as the Value.\\nSelect Save secret.\\n When adding workspace secrets in the LangSmith UI, make sure the secret keys match the environment variable names expected by your model provider.\\u200b2. Create a prompt\\nIn the LangSmith UI, navigate to the Prompts section in the left-hand menu.\\nClick on + Prompt to create a prompt.\\nModify the prompt by editing or adding prompts and input variables as needed.\\n\\u200b3. Test a prompt'),\n",
       " Document(id='649d1bd2-7058-4027-8fee-ebe8ee5e92d7', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/quickstarts/quickstart_ui', 'title': 'Prompt engineering quickstart - Docs by LangChain', 'language': 'en'}, page_content=\"Prompt engineering quickstart - Docs by LangChainSkip to main contentðŸš€ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangSmithSearch...âŒ˜KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationPrompt engineering quickstartGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupReferenceOverviewQuickstartConceptsCreate and update promptsCreate a promptManage promptsManage prompts programmaticallyConfigure prompt settingsUse tools in a promptInclude multimodal content in a promptWrite your prompt with AIConnect to modelsTutorialsOptimize a classifierSync prompts with GitHubTest multi-turn conversationsOn this pagePrerequisitesNext stepsVideo guidePrompt engineering quickstartCopy pageCopy pagePrompts guide the behavior of Large Language Models (LLM). Prompt engineering is the process of crafting, testing, and refining the instructions you give to an LLM so it produces reliable and useful responses.\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Query From a Vector DB\n",
    "query = \" navigate to the Prompts section of the left-hand sidebar and click on \"\n",
    "result = db.similarity_search(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3910375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Under the Prompts heading select the gear  icon next to the model name, which will launch the Prompt Settings window on the Model Configuration tab.\\n\\n\\nSet the model configuration you want to use. The Provider and Model you select will determine the parameters that are configurable on this configuration page. Once set, click Save as.\\n\\n\\n\\nSpecify the input variables you would like to test in the Inputs box and then click  Start.\\n\\nTo learn about more options for configuring your prompt in the Playground, refer to Configure prompt settings.\\n\\n\\nAfter testing and refining your prompt, click Save to store it for future use.\\n\\n\\u200b4. Iterate on a promptLangSmith allows for team-based prompt iteration. Workspace members can experiment with prompts in the playground and save their changes as a new commit when ready.To improve your prompts:\\n\\nReference the documentation provided by your model provider for best practices in prompt creation, such as:'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bda2ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True} client=<groq.resources.chat.completions.Completions object at 0x000002D396094B00> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002D3B5B82BA0> model_name='llama-3.1-8b-instant' model_kwargs={} groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model = \"llama-3.1-8b-instant\")\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a79823",
   "metadata": {},
   "source": [
    "# Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Based on the provided context, here's the answer to your question:\\n\\nLangChain is a framework for building applications with Large Language Models (LLMs). It provides a way to integrate LLMs into various applications and workflows, leveraging their capabilities to generate text, answer questions, and perform other language-related tasks.\\n\\nGroq helps by providing fast inference for LLMs, such as Llama 3, which means it accelerates the processing of LLMs' responses. This can be particularly useful for applications that require high-performance and low-latency language processing, such as chatbots, virtual assistants, and real-time language translation systems. By using Groq's fast inference capabilities, developers can build more efficient and scalable applications that can handle large volumes of language-based data and tasks.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 158, 'prompt_tokens': 91, 'total_tokens': 249, 'completion_time': 0.251227375, 'completion_tokens_details': None, 'prompt_time': 0.004941679, 'prompt_tokens_details': None, 'queue_time': 0.048931621, 'total_time': 0.256169054}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--fe6da1be-7416-44fc-ba4c-a982518f8531-0' usage_metadata={'input_tokens': 91, 'output_tokens': 158, 'total_tokens': 249}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "# Prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "# Compose runnable chain\n",
    "document_chain = prompt | llm\n",
    "\n",
    "# Example documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain is a framework for building applications with LLMs.\"),\n",
    "    Document(page_content=\"Groq provides fast inference for LLMs like Llama 3.\"),\n",
    "]\n",
    "\n",
    "# Convert documents into a single string\n",
    "context_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Run the chain\n",
    "question = \"What is LangChain and how does Groq help?\"\n",
    "\n",
    "result = document_chain.invoke({\n",
    "    \"context\": context_text,\n",
    "    \"input\": question\n",
    "})\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32d22140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df719c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2d395ffc920>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input --> Retrievers --> VectorStoreDB\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e946291e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m retriever = db.as_retriever()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_retrieval_chain\n\u001b[32m      3\u001b[39m retrieval_chain = create_retrieval_chain(retriever,document_chain)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever,document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43186ba3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'Ì£' (U+0323) (882800435.py, line 4)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mresponse[Ì£/ Ì£]\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character 'Ì£' (U+0323)\n"
     ]
    }
   ],
   "source": [
    "# Get the response from \n",
    "retrieval_chain.invoke(\"LangChain is a framework for building applications with LLMs\")\n",
    "response[\"answer\"]\n",
    "response[Ì£'context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f750e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
